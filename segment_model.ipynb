{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "U8e04H7YFbSi",
    "outputId": "1697917c-c774-4b78-db97-8cadd8a68faf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "train_path = '/content/drive/MyDrive/á„‡á…³á†¯á„…á…®á„†á…®á†«/á„‰á…µá†«á„‹á…­á†¼á„á…¡á„ƒá…³ á„‰á…¦á„€á…³á„†á…¥á†«á„á…³/card_train.csv'\n",
    "test_path = '/content/drive/MyDrive/á„‡á…³á†¯á„…á…®á„†á…®á†«/á„‰á…µá†«á„‹á…­á†¼á„á…¡á„ƒá…³ á„‰á…¦á„€á…³á„†á…¥á†«á„á…³/card_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "train_df.shape\n",
    "\n",
    "#ì‹œê³„ì—´ ë°ì´í„°\n",
    "for i in train_df.columns:\n",
    "  print(i)\n",
    "\n",
    "X = train_df.drop(columns=['ID', 'Unnamed: 0.1', 'Segment.1', 'Segment'])\n",
    "Y = train_df['Segment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYKJtFrPF4iA"
   },
   "source": [
    "ê¸ˆìœµ ì •ë³´ & ì—°ì²´/ì”ì•¡ ê´€ë ¨\n",
    "ì‹ ìš© ìœ„í—˜ & ê¸ˆìœµ ìŠµê´€ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNveTj6FF46i",
    "outputId": "35ab6568-6b11-497a-ddbd-18883a2c121e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 1) íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "train_path = '/content/drive/MyDrive/ë¸”ë£¨ë¬¸/ì‹ ìš©ì¹´ë“œ ì„¸ê·¸ë¨¼íŠ¸/card_train.csv'\n",
    "test_path  = '/content/drive/MyDrive/ë¸”ë£¨ë¬¸/ì‹ ìš©ì¹´ë“œ ì„¸ê·¸ë¨¼íŠ¸/card_test.csv'\n",
    "\n",
    "# 2) ë°ì´í„° ë¡œë“œ\n",
    "train = pd.read_csv(train_path)\n",
    "test  = pd.read_csv(test_path)\n",
    "\n",
    "# 3) ê¸ˆìœµì •ë³´_ì—°ì²´ì”ì•¡ í‚¤ì›Œë“œ ì •ì˜\n",
    "keywords = [\n",
    "    'í•œë„','ì´ììœ¨','RVì•½ì •ì²­êµ¬ìœ¨','RVìµœì†Œê²°ì œë¹„ìœ¨',\n",
    "    'ì”ì•¡','í‰ì”','ë³€ë™ë¥ ','ì—°ì²´','RP'\n",
    "]\n",
    "\n",
    "# 4) trainì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ì»¬ëŸ¼ ì¶”ì¶œ\n",
    "financial_train = [c for c in train.columns if any(k in c for k in keywords)]\n",
    "\n",
    "# 5) testì—ë„ ë™ì¼í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ (trainâ†”test ê°„ mismatch ë°©ì§€)\n",
    "financial_common = [c for c in financial_train if c in test.columns]\n",
    "\n",
    "print(f\"ë§¤ì¹­ëœ ê³µí†µ ì»¬ëŸ¼ ìˆ˜: {len(financial_common)}ê°œ\")\n",
    "print(financial_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f36osMlrGIvx",
    "outputId": "cc1281f6-164b-40d0-92f5-d3c33a2ddd9d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "train_path = '/content/drive/MyDrive/á„‡á…³á†¯á„…á…®á„†á…®á†«/á„‰á…µá†«á„‹á…­á†¼á„á…¡á„ƒá…³ á„‰á…¦á„€á…³á„†á…¥á†«á„á…³/card_train.csv'\n",
    "test_path = '/content/drive/MyDrive/á„‡á…³á†¯á„…á…®á„†á…®á†«/á„‰á…µá†«á„‹á…­á†¼á„á…¡á„ƒá…³ á„‰á…¦á„€á…³á„†á…¥á†«á„á…³/card_test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "# 2. ê¸ˆìœµì •ë³´_ì—°ì²´ ê´€ë ¨ í‚¤ì›Œë“œë¡œ ì»¬ëŸ¼ í•„í„°ë§\n",
    "keywords = ['í•œë„','ì´ììœ¨','RVì•½ì •ì²­êµ¬ìœ¨','RVìµœì†Œê²°ì œë¹„ìœ¨','ì”ì•¡','í‰ì”','ë³€ë™ë¥ ','ì—°ì²´','RP']\n",
    "financial_common = [col for col in train.columns if any(k in col for k in keywords)]\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ê°œìˆ˜ ë° ë¹„ìœ¨ ê³„ì‚°\n",
    "missing_count = train[financial_common].isna().sum()\n",
    "missing_pct = (missing_count / len(train)) * 100\n",
    "\n",
    "# 4. ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬\n",
    "missing_df = pd.DataFrame({\n",
    "    'missing_count': missing_count,\n",
    "    'missing_pct(%)': missing_pct.round(2)\n",
    "}).sort_values(by='missing_pct(%)', ascending=False)\n",
    "\n",
    "# 5. ì¶œë ¥\n",
    "print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(train)}\")\n",
    "print(missing_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "collapsed": true,
    "id": "7XeTNyZnGJ7M",
    "outputId": "7871f136-8e64-4363-e535-c92a030d53a8"
   },
   "outputs": [],
   "source": [
    "# ì—°ì²´ì¼ì_B0M -> ì—°ì²´ ì—†ìŒ 0, ì—°ì²´ ìˆìŒ 1 ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "train['is_overdue_B0M'] = train['ì—°ì²´ì¼ì_B0M'].notnull().astype(int)\n",
    "print(train['is_overdue_B0M'].value_counts())\n",
    "\n",
    "# ê¸°ì¡´ ì»¬ëŸ¼ í•„í„°ë§ëœ ë°ì´í„° + ì—°ì²´ì¼ì íŒŒìƒ ë³€ìˆ˜\n",
    "x_train = train[financial_common + ['is_overdue_B0M']].copy()\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "HLMoJOMbGRT7",
    "outputId": "974c3bb0-fc15-436e-b85c-4ee0c9edebb9"
   },
   "outputs": [],
   "source": [
    "# object í™•ì¸\n",
    "x_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf0gYN9FGTHa",
    "outputId": "d8f2ab5b-5958-4e32-d6e2-bb47f6327048"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. object íƒ€ì… ì»¬ëŸ¼ ì¶”ì¶œ\n",
    "object_cols = x_train.select_dtypes(include='object').columns\n",
    "print(f\"ì¸ì½”ë”© ëŒ€ìƒ ì»¬ëŸ¼: {list(object_cols)}\")\n",
    "\n",
    "# 2. ê° ì»¬ëŸ¼ë³„ LabelEncoder ì ìš©\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    x_train[col] = le.fit_transform(x_train[col].astype(str))  # NaN ë°©ì§€ ìœ„í•´ ë¬¸ìì—´ë¡œ ì²˜ë¦¬\n",
    "\n",
    "print(x_train[object_cols].head())\n",
    "\n",
    "y_train = train['Segment']\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soHn78ixGW19"
   },
   "source": [
    "train set í›ˆë ¨/ê²€ì¦ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg91RzTPGWSy",
    "outputId": "0c041278-df0e-40b7-9267-98e0ed2503bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. íƒ€ê¹ƒ ì´ì§„í™”: E â†’ 1, ë‚˜ë¨¸ì§€(A~D) â†’ 0\n",
    "y_binary = (y_train == 'E').astype(int)\n",
    "\n",
    "# 2. í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬ (ì „ì²´ì˜ 20%ë¥¼ ê²€ì¦ìš©)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    x_train, y_binary,\n",
    "    test_size=0.2,\n",
    "    stratify=y_binary,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •)\n",
    "clf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# 4. ì˜ˆì¸¡\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# 5. ì„±ëŠ¥ í‰ê°€\n",
    "print(\" [Classification Report]\")\n",
    "print(classification_report(y_val, y_pred, target_names=['Non-E', 'E']))\n",
    "\n",
    "print(\"\\n [Confusion Matrix]\")\n",
    "print(confusion_matrix(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjLbdNFeGaqE"
   },
   "source": [
    "2ë‹¨ê³„ ë©€í‹°í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (A/B/C/D)\n",
    "ì—¬ê¸°ì„œ a,bì˜ˆì¸¡ ì‹¤íŒ¨ + c,d ë¶ˆê· í˜•ìœ¼ë¡œ dê°€ ë§ì•„ í¸í–¥ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_N2-RhjGvm6",
    "outputId": "764d3796-3058-4b54-a12c-8b5f2c46fd5c"
   },
   "outputs": [],
   "source": [
    "# 1ë‹¨ê³„ ë¶„ë¥˜ìš© E ì—¬ë¶€ ë ˆì´ë¸” ìƒì„±\n",
    "y_binary = (y_train == 'E').astype(int)\n",
    "\n",
    "# â›³ Eê°€ ì•„ë‹Œ ë°ì´í„°ë§Œ ì¶”ì¶œ (1ë‹¨ê³„ ëª¨ë¸ì—ì„œ Non-Eì— í•´ë‹¹)\n",
    "non_e_mask = y_train != 'E'\n",
    "x_train_non_e = x_train[non_e_mask]        # ì„¤ëª…ë³€ìˆ˜\n",
    "y_train_non_e = y_train[non_e_mask]        # ì›ë˜ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë ˆì´ë¸” (A, B, C, D ì¤‘ í•˜ë‚˜)\n",
    "\n",
    "# ì´í›„ 2ë‹¨ê³„ ë¶„ë¥˜ ìˆ˜í–‰\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬\n",
    "X2_tr, X2_val, y2_tr, y2_val = train_test_split(\n",
    "    x_train_non_e, y_train_non_e,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_non_e,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "clf_multi = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_multi.fit(X2_tr, y2_tr)\n",
    "\n",
    "# í‰ê°€\n",
    "y2_pred = clf_multi.predict(X2_val)\n",
    "\n",
    "print(\"[2ë‹¨ê³„ Classification Report]\")\n",
    "print(classification_report(y2_val, y2_pred))\n",
    "print(\"[2ë‹¨ê³„ Confusion Matrix]\")\n",
    "print(confusion_matrix(y2_val, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-g5xTfCHGTa"
   },
   "source": [
    "a/b ë¥¼ abë¡œ ë³‘í•©\n",
    "\n",
    "í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬ (d,c,ab)\n",
    "ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (randomforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIR4r-lLHHom",
    "outputId": "61f56abd-9a41-40a2-aae6-01de24afa9b1"
   },
   "outputs": [],
   "source": [
    "# A/Bë¥¼ 'AB'ë¡œ ë³‘í•©\n",
    "y_train_non_e_3class = y_train_non_e.replace({'A': 'AB', 'B': 'AB'})\n",
    "print(y_train_non_e_3class.value_counts())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ë¶„ë¦¬\n",
    "X3_tr, X3_val, y3_tr, y3_val = train_test_split(\n",
    "    x_train_non_e, y_train_non_e_3class,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_non_e_3class,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "clf_3class = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# í•™ìŠµ\n",
    "clf_3class.fit(X3_tr, y3_tr)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y3_pred = clf_3class.predict(X3_val)\n",
    "\n",
    "# í‰ê°€\n",
    "print(\"[3ë¶„ë¥˜ Classification Report]\")\n",
    "print(classification_report(y3_val, y3_pred))\n",
    "\n",
    "print(\"\\n[3ë¶„ë¥˜ Confusion Matrix]\")\n",
    "print(confusion_matrix(y3_val, y3_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Ufa4UMHa47"
   },
   "source": [
    "LightGBMìœ¼ë¡œ ëª¨ë¸êµì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lmGpNcZHHbx9",
    "outputId": "d84f4531-08f8-4a8b-c885-a15d22cd90ca"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. ë°ì´í„°: ê¸°ì¡´ Non-E ëŒ€ìƒ + AB ë³‘í•© ì™„ë£Œëœ íƒ€ê¹ƒ\n",
    "# x_train_non_e, y_train_non_e_3class\n",
    "\n",
    "# 2. í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬\n",
    "X3_tr, X3_val, y3_tr, y3_val = train_test_split(\n",
    "    x_train_non_e, y_train_non_e_3class,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_non_e_3class,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜\n",
    "lgbm = LGBMClassifier(\n",
    "    class_weight='balanced',   # í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ\n",
    "lgbm.fit(X3_tr, y3_tr)\n",
    "\n",
    "# 5. ì˜ˆì¸¡\n",
    "y3_pred_lgbm = lgbm.predict(X3_val)\n",
    "\n",
    "# 6. í‰ê°€\n",
    "print(\"[3-Class Classification Report - LightGBM]\")\n",
    "print(classification_report(y3_val, y3_pred_lgbm))\n",
    "\n",
    "print(\"\\n[Confusion Matrix - LightGBM]\")\n",
    "print(confusion_matrix(y3_val, y3_pred_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjWNorUEHfO3"
   },
   "source": [
    "XGBoostë¡œ ëª¨ë¸êµì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_Ly_FdyHj6y",
    "outputId": "499d1ca2-b816-45e7-ae07-4b27b8f1854c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. íƒ€ê¹ƒê°’ ë ˆì´ë¸” ì¸ì½”ë”© (AB/C/D â†’ 0/1/2)\n",
    "le_y3 = LabelEncoder()\n",
    "y3_tr_encoded = le_y3.fit_transform(y3_tr)\n",
    "y3_val_encoded = le_y3.transform(y3_val)\n",
    "\n",
    "# 2. XGBoost ëª¨ë¸ í•™ìŠµ\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X3_tr, y3_tr_encoded)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y3_pred_xgb = xgb_clf.predict(X3_val)\n",
    "\n",
    "# 4. ë””ì½”ë”© (ìˆ«ì â†’ AB/C/D)\n",
    "y3_pred_decoded = le_y3.inverse_transform(y3_pred_xgb)\n",
    "\n",
    "# 5. í‰ê°€\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"[3-Class Classification Report - XGBoost]\")\n",
    "print(classification_report(y3_val, y3_pred_decoded))\n",
    "\n",
    "print(\"\\n[Confusion Matrix - XGBoost]\")\n",
    "print(confusion_matrix(y3_val, y3_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzaKXkakHoRF"
   },
   "outputs": [],
   "source": [
    "!apt-get -qq install -y fonts-nanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "collapsed": true,
    "id": "JdTYcuMvHtcn",
    "outputId": "00302145-331d-423b-a7be-cd0a66349774"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# âœ… ì„¤ì¹˜ëœ ê²½ë¡œ ì§ì ‘ ì§€ì •\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# âœ… ì „ì—­ ì„¤ì •\n",
    "plt.rcParams['font.family'] = font_name\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.title('í•œê¸€ í°íŠ¸ í…ŒìŠ¤íŠ¸')\n",
    "plt.plot([1, 2, 3], [1, 4, 9])\n",
    "plt.xlabel('Xì¶•')\n",
    "plt.ylabel('Yì¶•')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM6B8YS-Hv4M"
   },
   "source": [
    "RFëª¨ë¸ì˜ FIë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "collapsed": true,
    "id": "4X6-NzWKHxyf",
    "outputId": "dbe6eb0b-dcf1-4b1b-e52a-c72e392d2f80"
   },
   "outputs": [],
   "source": [
    "!apt-get -qq install -y fonts-nanum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# âœ… Feature importance ì¶”ì¶œ\n",
    "importances = clf_3class.feature_importances_\n",
    "feature_names = X3_tr.columns\n",
    "fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# âœ… ì¤‘ìš”ë„ ìˆœ ì •ë ¬\n",
    "fi_df = fi_df.sort_values(by='Importance', ascending=False).head(30)\n",
    "\n",
    "# âœ… ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=fi_df)\n",
    "plt.title('Top 30 Feature Importances (RandomForest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# âœ… ì£¼ìš” ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\"ì£¼ìš” ë³€ìˆ˜ ìƒìœ„ 30ê°œ:\")\n",
    "for i, feature in enumerate(fi_df['Feature'].values, start=1):\n",
    "    print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmZhAQtxHzOR"
   },
   "source": [
    "lightGBMì˜ FIë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "collapsed": true,
    "id": "rlj8ohMxH0Sv",
    "outputId": "f52125c6-bb43-4876-d8df-f1820986f8a0"
   },
   "outputs": [],
   "source": [
    "# âœ… 1. Feature Importance ì¶”ì¶œ\n",
    "lgb_importances = lgbm.feature_importances_\n",
    "lgb_feature_names = X3_tr.columns\n",
    "\n",
    "lgb_fi_df = pd.DataFrame({\n",
    "    'Feature': lgb_feature_names,\n",
    "    'Importance': lgb_importances\n",
    "})\n",
    "\n",
    "# âœ… 2. ì¤‘ìš”ë„ ìˆœ ì •ë ¬\n",
    "lgb_fi_df = lgb_fi_df.sort_values(by='Importance', ascending=False).head(30)\n",
    "\n",
    "# âœ… 3. ì£¼ìš” ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (ë²ˆí˜¸ í¬í•¨)\n",
    "print(\"LightGBM ì¤‘ìš” ë³€ìˆ˜ Top 30 ë¦¬ìŠ¤íŠ¸:\")\n",
    "for i, feature in enumerate(lgb_fi_df['Feature'].values, start=1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "# âœ… 4. ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=lgb_fi_df)\n",
    "plt.title('Top 30 Feature Importances (LightGBM)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uieptN6EH3uK"
   },
   "source": [
    "XGBoostì˜ FIë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "collapsed": true,
    "id": "RXJleBGMH4nw",
    "outputId": "009a53e0-5111-4bd8-c80f-f7fe9292b088"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… 1. Feature Importance ì¶”ì¶œ\n",
    "xgb_importances = xgb_clf.feature_importances_\n",
    "xgb_feature_names = X3_tr.columns\n",
    "\n",
    "xgb_fi_df = pd.DataFrame({\n",
    "    'Feature': xgb_feature_names,\n",
    "    'Importance': xgb_importances\n",
    "})\n",
    "\n",
    "# âœ… 2. ì¤‘ìš”ë„ ìˆœ ì •ë ¬\n",
    "xgb_fi_df = xgb_fi_df.sort_values(by='Importance', ascending=False).head(30)\n",
    "\n",
    "# âœ… 3. ì£¼ìš” ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (ë²ˆí˜¸ í¬í•¨)\n",
    "print(\"XGBoost ì¤‘ìš” ë³€ìˆ˜ Top 30 ë¦¬ìŠ¤íŠ¸:\")\n",
    "for i, feature in enumerate(xgb_fi_df['Feature'].values, start=1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "# âœ… 4. ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=xgb_fi_df)\n",
    "plt.title('Top 30 Feature Importances (XGBoost)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61vW_F07H7Cl"
   },
   "source": [
    "3ê°€ì§€ ëª¨ë¸ì˜ FI ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "yBjlUMGEH8kI",
    "outputId": "7c69f92e-e255-402b-f4e6-58fdfa7f5fe2"
   },
   "outputs": [],
   "source": [
    "# ğŸ“Œ 1. ì„¸ ëª¨ë¸ì˜ Top 30 ì¤‘ìš” ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸\n",
    "rf_top_features = fi_df['Feature'].head(30).tolist()\n",
    "xgb_top_features = xgb_fi_df['Feature'].head(30).tolist()\n",
    "lgb_top_features = lgb_fi_df['Feature'].head(30).tolist()\n",
    "\n",
    "# ğŸ“Œ 2. ê³µí†µ ë³€ìˆ˜\n",
    "common_all = list(set(rf_top_features) & set(xgb_top_features) & set(lgb_top_features))\n",
    "common_rf_xgb = list(set(rf_top_features) & set(xgb_top_features) - set(lgb_top_features))\n",
    "common_rf_lgb = list(set(rf_top_features) & set(lgb_top_features) - set(xgb_top_features))\n",
    "common_xgb_lgb = list(set(xgb_top_features) & set(lgb_top_features) - set(rf_top_features))\n",
    "\n",
    "# ğŸ“Œ 3. ê³ ìœ  ë³€ìˆ˜\n",
    "rf_only = list(set(rf_top_features) - set(xgb_top_features) - set(lgb_top_features))\n",
    "xgb_only = list(set(xgb_top_features) - set(rf_top_features) - set(lgb_top_features))\n",
    "lgb_only = list(set(lgb_top_features) - set(rf_top_features) - set(xgb_top_features))\n",
    "\n",
    "# ğŸ“Œ 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ”— [ê³µí†µ ì¤‘ìš” ë³€ìˆ˜ - RF, XGB, LGB]\")\n",
    "for i, feat in enumerate(common_all, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nğŸ”— [ê³µí†µ ì¤‘ìš” ë³€ìˆ˜ - RF & XGB]\")\n",
    "for i, feat in enumerate(common_rf_xgb, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nğŸ”— [ê³µí†µ ì¤‘ìš” ë³€ìˆ˜ - RF & LGB]\")\n",
    "for i, feat in enumerate(common_rf_lgb, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nğŸ”— [ê³µí†µ ì¤‘ìš” ë³€ìˆ˜ - XGB & LGB]\")\n",
    "for i, feat in enumerate(common_xgb_lgb, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nâ— [RF ë‹¨ë… ì¤‘ìš” ë³€ìˆ˜]\")\n",
    "for i, feat in enumerate(rf_only, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nâ— [XGB ë‹¨ë… ì¤‘ìš” ë³€ìˆ˜]\")\n",
    "for i, feat in enumerate(xgb_only, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "print(\"\\nâ— [LGB ë‹¨ë… ì¤‘ìš” ë³€ìˆ˜]\")\n",
    "for i, feat in enumerate(lgb_only, 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZQae62NH9s3"
   },
   "source": [
    "top30 ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYbzHot5H_lD"
   },
   "outputs": [],
   "source": [
    "# ê° ëª¨ë¸ì˜ FI ìƒìœ„ 30ê°œ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸\n",
    "rf_top30 = fi_df['Feature'].head(30).tolist()\n",
    "xgb_top30 = xgb_fi_df['Feature'].head(30).tolist()\n",
    "lgb_top30 = lgb_fi_df['Feature'].head(30).tolist()\n",
    "\n",
    "# ì „ì²´ì—ì„œ ë¹ˆë„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ Top 30 ë³€ìˆ˜ ì„ ì •\n",
    "from collections import Counter\n",
    "\n",
    "# ë³€ìˆ˜ë“¤ ëª¨ì•„ì„œ ë¹ˆë„ ê³„ì‚°\n",
    "all_top_features = rf_top30 + xgb_top30 + lgb_top30\n",
    "top_30_features = [item[0] for item in Counter(all_top_features).most_common(30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Riwsk8uSITt4"
   },
   "source": [
    "3ê°€ì§€ ëª¨ë¸ FIë¶„ì„ - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "collapsed": true,
    "id": "G-ijRZkXIU4n",
    "outputId": "dc4c2c1e-7f1b-4e19-a62f-af2fa76c5e7a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ìœ¼ë¡œ í•„í„°ë§\n",
    "top_30_features_valid = [col for col in top_30_features if col in X3_tr.columns]\n",
    "\n",
    "# âœ… ë°ì´í„° ì¶”ì¶œ\n",
    "X3_tr_top30 = X3_tr[top_30_features_valid]\n",
    "X3_val_top30 = X3_val[top_30_features_valid]\n",
    "\n",
    "# âœ… ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "rf_top30 = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf_top30.fit(X3_tr_top30, y3_tr)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡\n",
    "y_pred_top30 = rf_top30.predict(X3_val_top30)\n",
    "\n",
    "# âœ… ì„±ëŠ¥ í‰ê°€\n",
    "report_top30 = classification_report(y3_val, y_pred_top30, output_dict=True)\n",
    "report_df = pd.DataFrame(report_top30).transpose()\n",
    "\n",
    "# âœ… ì „ì²´ ì§€í‘œ ì¶œë ¥\n",
    "print(\"[Top 30 Feature ê¸°ë°˜ RandomForest ì„±ëŠ¥ í‰ê°€]\")\n",
    "display(report_df.round(3))  # ì†Œìˆ˜ì  3ìë¦¬ë¡œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "\n",
    "# âœ… ì •í™•ë„ ë° f1-score ì‹œê°í™”ìš© ë°ì´í„° êµ¬ì„±\n",
    "scores = {\n",
    "    'accuracy': report_df.loc['accuracy']['precision'],\n",
    "    'f1-score': report_df.loc['weighted avg']['f1-score']\n",
    "}\n",
    "score_df = pd.DataFrame(list(scores.items()), columns=['Metric', 'Score'])\n",
    "\n",
    "# âœ… ì‹œê°í™”\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score', palette='Blues_d')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Top 30 Feature ê¸°ë°˜ RandomForest ì„±ëŠ¥')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVJCSHSfIW67"
   },
   "source": [
    "3ê°€ì§€ ëª¨ë¸ FIë¶„ì„ - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "collapsed": true,
    "id": "bF9iQtTBIYFR",
    "outputId": "a25de0b5-c76d-4672-fc19-99db08f53ba9"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_enc = le.fit_transform(y3_tr)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# âœ… ìœ íš¨í•œ feature í•„í„°ë§\n",
    "top_30_features_valid = [col for col in top_30_features if col in X3_tr.columns]\n",
    "X3_tr_top30 = X3_tr[top_30_features_valid]\n",
    "X3_val_top30 = X3_val[top_30_features_valid]\n",
    "\n",
    "# âœ… ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "xgb_top30 = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_top30.fit(X3_tr_top30, y3_tr_enc)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡\n",
    "y_pred_top30_enc = xgb_top30.predict(X3_val_top30)\n",
    "y_pred_top30 = le.inverse_transform(y_pred_top30_enc)\n",
    "\n",
    "# âœ… í‰ê°€\n",
    "report_top30 = classification_report(y3_val, y_pred_top30, output_dict=True)\n",
    "report_df = pd.DataFrame(report_top30).transpose()\n",
    "\n",
    "# âœ… ì •í™•ë„ ë° f1-score ì‹œê°í™”ìš© ë°ì´í„° êµ¬ì„±\n",
    "scores = {\n",
    "    'accuracy': report_df.loc['accuracy']['precision'],\n",
    "    'f1-score': report_df.loc['weighted avg']['f1-score']\n",
    "}\n",
    "score_df = pd.DataFrame(list(scores.items()), columns=['Metric', 'Score'])\n",
    "\n",
    "# âœ… ì‹œê°í™”\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Top 30 Feature ê¸°ë°˜ XGBoost ì„±ëŠ¥')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# âœ… ìƒì„¸ ë³´ê³ ì„œ ì¶œë ¥\n",
    "print(\"XGBoost í‰ê°€ ìƒì„¸ ê²°ê³¼ (Top 30 Feature)\")\n",
    "print(report_df[['precision', 'recall', 'f1-score']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReJHkMgJIa5P"
   },
   "source": [
    "SMOTE -> AB ë°ì´í„° ì¦ê°•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzSmnrTgIb6f",
    "outputId": "706c75ab-359f-4c5d-cb9d-f271efbe6ba4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° 0ìœ¼ë¡œ ëŒ€ì²´ (ì˜ˆ: ì—°ì²´ ê´€ë ¨ íŒŒìƒ ë³€ìˆ˜)\n",
    "X3_tr = X3_tr.fillna(0)\n",
    "\n",
    "# SMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(\"Before SMOTE:\", Counter(y3_tr))\n",
    "\n",
    "# SMOTE ê°ì²´ ìƒì„± ë° ì ìš©\n",
    "smote = SMOTE(random_state=42)\n",
    "X3_tr_smote, y3_tr_smote = smote.fit_resample(X3_tr, y3_tr)\n",
    "\n",
    "# SMOTE ì ìš© í›„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(\"After SMOTE:\", Counter(y3_tr_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R0sgYHQIfIh"
   },
   "source": [
    "SMOTE í›„ RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "hlL67s7CIgMh",
    "outputId": "d770562e-bb11-47ec-d50e-7b2d0e3b8b41"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X3_tr_clean = X3_tr.fillna(0)\n",
    "X3_val_clean = X3_val.fillna(0)\n",
    "\n",
    "# 2. SMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(\"Before SMOTE:\", Counter(y3_tr))\n",
    "\n",
    "# 3. SMOTE ì ìš©\n",
    "smote = SMOTE(random_state=42)\n",
    "X3_tr_smote, y3_tr_smote = smote.fit_resample(X3_tr_clean, y3_tr)\n",
    "\n",
    "print(\"After SMOTE:\", Counter(y3_tr_smote))\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ\n",
    "rf_smote = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf_smote.fit(X3_tr_smote, y3_tr_smote)\n",
    "\n",
    "# 5. ê²€ì¦ ì„¸íŠ¸ ì»¬ëŸ¼ ë§ì¶¤\n",
    "X3_val_aligned = X3_val_clean[X3_tr_smote.columns]\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 6. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y3_pred_smote = rf_smote.predict(X3_val_aligned)\n",
    "\n",
    "# Classification Report ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - RandomForest]\")\n",
    "print(classification_report(y3_val, y3_pred_smote, digits=2))\n",
    "\n",
    "# Confusion Matrix ì¶œë ¥\n",
    "cm = confusion_matrix(y3_val, y3_pred_smote, labels=rf_smote.classes_)\n",
    "print(\"\\n[Confusion Matrix - RandomForest]\")\n",
    "print(\"Labels:\", rf_smote.classes_.tolist())\n",
    "print(cm)\n",
    "\n",
    "# 7. ì •í™•ë„ ë° f1-score ì‹œê°í™”\n",
    "score_dict = {\n",
    "    'accuracy': report_df.loc['accuracy']['precision'],\n",
    "    'f1-score': report_df.loc['weighted avg']['f1-score']\n",
    "}\n",
    "score_df = pd.DataFrame(score_dict.items(), columns=['Metric', 'Score'])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('RandomForest ì„±ëŠ¥ (SMOTE ì ìš© í›„)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "print(\"SMOTE ì ìš© í›„ RandomForest ìƒì„¸ ì„±ëŠ¥:\")\n",
    "print(report_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKeO2oGzIih-"
   },
   "source": [
    "SMOTE í›„ Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "kc6-78uEIjkg",
    "outputId": "0261002e-dbe6-4d30-ba07-55435b25c93c"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X3_tr_clean = X3_tr.fillna(0)\n",
    "X3_val_clean = X3_val.fillna(0)\n",
    "\n",
    "# 2. SMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(\"Before SMOTE:\", Counter(y3_tr))\n",
    "\n",
    "# 3. SMOTE ì ìš©\n",
    "smote = SMOTE(random_state=42)\n",
    "X3_tr_smote, y3_tr_smote = smote.fit_resample(X3_tr_clean, y3_tr)\n",
    "\n",
    "print(\"After SMOTE:\", Counter(y3_tr_smote))\n",
    "\n",
    "# 4. Label Encoding\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_encoded = le.fit_transform(y3_tr_smote)\n",
    "y3_val_encoded = le.transform(y3_val)\n",
    "\n",
    "# 5. XGBoost ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "xgb_smote = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_smote.fit(X3_tr_smote, y3_tr_smote_encoded)\n",
    "\n",
    "# 6. ê²€ì¦ ë°ì´í„° ì»¬ëŸ¼ ì •ë ¬\n",
    "X3_val_fixed = X3_val_clean[X3_tr_smote.columns]\n",
    "\n",
    "# 7. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y3_pred_encoded = xgb_smote.predict(X3_val_fixed)\n",
    "y3_pred = le.inverse_transform(y3_pred_encoded)\n",
    "\n",
    "# 8. ì„±ëŠ¥ í‰ê°€\n",
    "report_xgb = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_xgb = pd.DataFrame(report_xgb).transpose()\n",
    "\n",
    "# 9. ì„±ëŠ¥ ì‹œê°í™”\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df_xgb.loc['accuracy']['precision'], report_df_xgb.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ XGBoost ì„±ëŠ¥')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - XGBoost]\")\n",
    "print(classification_report(y3_val, y3_pred, digits=2))\n",
    "\n",
    "# 11. Confusion Matrix ì¶œë ¥\n",
    "cm = confusion_matrix(y3_val, y3_pred, labels=le.classes_)\n",
    "print(\"\\n[Confusion Matrix - XGBoost]\")\n",
    "print(\"Labels:\", le.classes_.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2A68E9WsInhm",
    "outputId": "141b43c8-3267-47fa-e21d-fed46ab623e7"
   },
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESIrifJUIo1E"
   },
   "source": [
    "catboostë¡œ ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "N6gZgG3RItcL",
    "outputId": "a2bab57d-f608-4176-e5b6-d90c6de87cac"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X3_tr_clean = X3_tr.fillna(0)\n",
    "X3_val_clean = X3_val.fillna(0)\n",
    "\n",
    "# 2. SMOTE ì ìš© ì „ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(\"Before SMOTE:\", Counter(y3_tr))\n",
    "\n",
    "# 3. SMOTE ì ìš©\n",
    "smote = SMOTE(random_state=42)\n",
    "X3_tr_smote, y3_tr_smote = smote.fit_resample(X3_tr_clean, y3_tr)\n",
    "\n",
    "print(\"After SMOTE:\", Counter(y3_tr_smote))\n",
    "\n",
    "# 4. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_encoded = le.fit_transform(y3_tr_smote)\n",
    "y3_val_encoded = le.transform(y3_val)\n",
    "\n",
    "# 5. CatBoost ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "cat_model.fit(X3_tr_smote, y3_tr_smote_encoded)\n",
    "\n",
    "# 6. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y3_pred_encoded = cat_model.predict(X3_val_clean)\n",
    "y3_pred = le.inverse_transform(y3_pred_encoded.flatten())\n",
    "\n",
    "# 7. ì„±ëŠ¥ í‰ê°€\n",
    "report_cat = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_cat = pd.DataFrame(report_cat).transpose()\n",
    "\n",
    "# 8. ì„±ëŠ¥ ì‹œê°í™”\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df_cat.loc['accuracy']['precision'], report_df_cat.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ CatBoost ì„±ëŠ¥')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. ìƒì„¸ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - CatBoost]\")\n",
    "print(classification_report(y3_val, y3_pred, digits=2))\n",
    "\n",
    "# 10. Confusion Matrix ì¶œë ¥\n",
    "cm = confusion_matrix(y3_val, y3_pred, labels=le.classes_)\n",
    "print(\"\\n[Confusion Matrix - CatBoost]\")\n",
    "print(\"Labels:\", le.classes_.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jv8uwfSqIu-O"
   },
   "source": [
    "CatBoost í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (smote X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdJtnKsRIv5A",
    "outputId": "1813ad88-2364-4f98-be48-fbc9649b83d1"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X3_tr_clean = X3_tr.fillna(0)\n",
    "X3_val_clean = X3_val.fillna(0)\n",
    "\n",
    "# 2. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_encoded = le.fit_transform(y3_tr)\n",
    "y3_val_encoded = le.transform(y3_val)\n",
    "\n",
    "# 3. CatBoost ëª¨ë¸ ì •ì˜ (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    auto_class_weights='Balanced',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ\n",
    "cat_model.fit(X3_tr_clean, y3_tr_encoded)\n",
    "\n",
    "# 5. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y3_pred_encoded = cat_model.predict(X3_val_clean)\n",
    "y3_pred = le.inverse_transform(y3_pred_encoded.flatten())\n",
    "\n",
    "# 6. ì„±ëŠ¥ í‰ê°€\n",
    "report_cat = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_cat = pd.DataFrame(report_cat).transpose()\n",
    "\n",
    "# 7. ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - CatBoost (Class Weight)]\")\n",
    "print(report_df_cat[['precision', 'recall', 'f1-score']].round(3))\n",
    "\n",
    "# 8. Confusion Matrix\n",
    "cm = confusion_matrix(y3_val, y3_pred, labels=le.classes_)\n",
    "print(\"\\n[Confusion Matrix - CatBoost (Class Weight)]\")\n",
    "print(f\"Labels: {list(le.classes_)}\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRuS9S5Jb_he"
   },
   "source": [
    "í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê¸°ë°˜ XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKpBmZ7sb-US",
    "outputId": "da6551e3-8bf2-4abf-defc-b342ff9a6906"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 1. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_encoded = le.fit_transform(y3_tr)\n",
    "y3_val_encoded = le.transform(y3_val)\n",
    "\n",
    "# 2. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ â†’ sample_weight ê³„ì‚°\n",
    "sample_weight = compute_sample_weight(class_weight='balanced', y=y3_tr_encoded)\n",
    "\n",
    "# 3. XGBoost ëª¨ë¸ ì •ì˜\n",
    "xgb_weighted = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. í•™ìŠµ\n",
    "xgb_weighted.fit(X3_tr, y3_tr_encoded, sample_weight=sample_weight)\n",
    "\n",
    "# 5. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y3_pred_encoded = xgb_weighted.predict(X3_val)\n",
    "y3_pred = le.inverse_transform(y3_pred_encoded)\n",
    "\n",
    "# 6. ì„±ëŠ¥ í‰ê°€\n",
    "report = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 7. ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - XGBoost (Class Weight)]\")\n",
    "print(report_df[['precision', 'recall', 'f1-score']].round(3))\n",
    "\n",
    "# 8. Confusion Matrix\n",
    "cm = confusion_matrix(y3_val, y3_pred, labels=le.classes_)\n",
    "print(\"\\n[Confusion Matrix - XGBoost (Class Weight)]\")\n",
    "print(f\"Labels: {list(le.classes_)}\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LG-6SpyaddL4"
   },
   "source": [
    "SMOTE : XGBoost + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648,
     "referenced_widgets": [
      "4dbc44e74fc247f38058eeef75558c65",
      "036551ce0cad417a9ac5a131fd9823e9",
      "b20a2a3a33a948f590acd955b557e6e9",
      "40c4a15d362244fb9b1e651d3fec6ded",
      "1d85846c7f4a4445a6da68dda6562310",
      "740c36892d924d46b1d032b7b5ba771f",
      "2416f3ad2ac049318ebf450d16092060",
      "63038d3223d24b7f8e3c0c1191952ec6",
      "c5786d16573946d9a57c858a5f6c14a9",
      "a857fc705aa048fcad88f76ad26f3d77",
      "908fa80af4a548b990a740bf69dc9b29"
     ]
    },
    "id": "KnkZnyJhhKS-",
    "outputId": "d85f5176-cf2a-47fa-a65e-5e0eb23b8d76"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_enc = le.fit_transform(y3_tr_smote)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# 2. íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ ì •ì˜\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'reg_alpha': uniform(0, 5),\n",
    "    'reg_lambda': uniform(0, 5)\n",
    "}\n",
    "\n",
    "# 3. XGBoost ëª¨ë¸ ì •ì˜\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# 4. RandomizedSearchCV ë˜í•‘ (ì§„í–‰ë¥  í‘œì‹œ í¬í•¨)\n",
    "class TqdmRandomizedSearchCV(RandomizedSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        with tqdm(total=self.n_iter, desc=\"âš¡ Random Search ì§„í–‰ì¤‘\") as pbar:\n",
    "            self._pbar = pbar\n",
    "            return super().fit(X, y, **fit_params)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        def wrapped(candidate_params):\n",
    "            results = evaluate_candidates(candidate_params)\n",
    "            self._pbar.update(len(candidate_params))\n",
    "            return results\n",
    "        return super()._run_search(wrapped)\n",
    "\n",
    "# 5. íƒìƒ‰ê¸° ì •ì˜ ë° í•™ìŠµ ì‹œì‘\n",
    "random_search = TqdmRandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # íƒìƒ‰ íšŸìˆ˜: 20ê°œ\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X3_tr_smote, y3_tr_smote_enc)\n",
    "\n",
    "# 6. ìµœì  ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "best_xgb = random_search.best_estimator_\n",
    "y3_pred_enc = best_xgb.predict(X3_val)\n",
    "y3_pred = le.inverse_transform(y3_pred_enc)\n",
    "\n",
    "# 7. ë¦¬í¬íŠ¸ ë° ì‹œê°í™”\n",
    "report_xgb = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_xgb = pd.DataFrame(report_xgb).transpose()\n",
    "\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df_xgb.loc['accuracy']['precision'], report_df_xgb.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ XGBoost ì„±ëŠ¥ (Random Search)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"XGBoost ìµœì  íŒŒë¼ë¯¸í„°:\", random_search.best_params_)\n",
    "print(\"XGBoost ì„±ëŠ¥ ìƒì„¸:\")\n",
    "print(report_df_xgb[['precision', 'recall', 'f1-score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI7MYbRYdoxh"
   },
   "source": [
    "SMOTE : CatBoost + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666,
     "referenced_widgets": [
      "f5fc6fca5e524c17b18cd7018b08bebb",
      "dbf4348bffa9401db9eb2404dd7abc13",
      "407b3d50a4c24b92896cc9efdca182b9",
      "b15e7ad3152e49e0aedadfded54d4bf8",
      "cd9764e2aab249dcb6c24f1fb742336f",
      "1869abb634c24d468c74d1c29ac0a298",
      "6c9ef6bb0f7f49a48c893df8669f1ac9",
      "e6c1681479f44803ac4900184bd0a204",
      "a330f78b88f34c8ab6d20eacec670a84",
      "dbeffc0787ae47fa9b26e1f4865b4f72",
      "61fa993bde954cf1b547fdafd1047197"
     ]
    },
    "id": "QAnBQp1Od1tm",
    "outputId": "17e867f3-4056-4264-c281-7c0be2cc5238"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_enc = le.fit_transform(y3_tr_smote)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# 2. íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ ì •ì˜\n",
    "param_dist = {\n",
    "    'depth': randint(4, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'iterations': randint(100, 500),\n",
    "    'l2_leaf_reg': uniform(1, 10),\n",
    "    'random_strength': uniform(0, 5)\n",
    "}\n",
    "\n",
    "# 3. CatBoost ëª¨ë¸ ì •ì˜\n",
    "cat_model = CatBoostClassifier(\n",
    "    loss_function='MultiClass',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 4. tqdm RandomizedSearchCV ë˜í•‘\n",
    "class TqdmRandomizedSearchCV(RandomizedSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        with tqdm(total=self.n_iter, desc=\"âš¡ Random Search ì§„í–‰ì¤‘ (CatBoost)\") as pbar:\n",
    "            self._pbar = pbar\n",
    "            return super().fit(X, y, **fit_params)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        def wrapped(candidate_params):\n",
    "            results = evaluate_candidates(candidate_params)\n",
    "            self._pbar.update(len(candidate_params))\n",
    "            return results\n",
    "        return super()._run_search(wrapped)\n",
    "\n",
    "# 5. íƒìƒ‰ê¸° ì •ì˜ ë° í•™ìŠµ\n",
    "random_search_cat = TqdmRandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_cat.fit(X3_tr_smote, y3_tr_smote_enc)\n",
    "\n",
    "# 6. ì˜ˆì¸¡\n",
    "best_cat = random_search_cat.best_estimator_\n",
    "y3_pred_enc = best_cat.predict(X3_val)\n",
    "y3_pred = le.inverse_transform(y3_pred_enc.flatten())\n",
    "\n",
    "# 7. í‰ê°€ ë° ì¶œë ¥\n",
    "report_cat = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_cat = pd.DataFrame(report_cat).transpose()\n",
    "\n",
    "print(\"CatBoost ìµœì  íŒŒë¼ë¯¸í„°:\", random_search_cat.best_params_)\n",
    "print(\"\\nCatBoost ì„±ëŠ¥ ìƒì„¸:\")\n",
    "print(report_df_cat[['precision', 'recall', 'f1-score']])\n",
    "\n",
    "# 8. ê°„ë‹¨ ì‹œê°í™”\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df_cat.loc['accuracy']['precision'], report_df_cat.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ CatBoost ì„±ëŠ¥ (Random Search)')\n",
    "plt.tight_layout()\n",
    "splt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoEytsSFMv31"
   },
   "source": [
    "Soft Voting ì•™ìƒë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "5DSmN1fkMunr",
    "outputId": "c42ecd49-f5ea-4f27-dc2e-ebc2fec9e37b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… 1. ë ˆì´ë¸” ì¸ì½”ë”© (ì´ë¯¸ í•œ ê²½ìš° ìƒëµ ê°€ëŠ¥)\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_enc = le.fit_transform(y3_tr_smote)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# âœ… 2. Soft Voting ì•™ìƒë¸” ì •ì˜\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),   # âœ… RandomizedSearchCV ê²°ê³¼ë¡œ ë„ì¶œëœ XGBoost\n",
    "        ('cat', best_cat)    # âœ… RandomizedSearchCV ê²°ê³¼ë¡œ ë„ì¶œëœ CatBoost\n",
    "    ],\n",
    "    voting='soft'  # í™•ë¥  í‰ê·  ë°©ì‹\n",
    ")\n",
    "\n",
    "# âœ… 3. í•™ìŠµ\n",
    "voting_model.fit(X3_tr_smote, y3_tr_smote_enc)\n",
    "\n",
    "# âœ… 4. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y_pred_ens_enc = voting_model.predict(X3_val)\n",
    "y_pred_ens = le.inverse_transform(y_pred_ens_enc)\n",
    "\n",
    "# âœ… 5. ë¦¬í¬íŠ¸ ë° ì¶œë ¥\n",
    "report_ens = classification_report(y3_val, y_pred_ens, output_dict=True)\n",
    "report_df_ens = pd.DataFrame(report_ens).transpose()\n",
    "\n",
    "print(\"\\nğŸ“Š [3-Class Classification Report - VotingClassifier (Soft)]\")\n",
    "print(report_df_ens[['precision', 'recall', 'f1-score']].round(3))\n",
    "\n",
    "# âœ… 6. Confusion Matrix\n",
    "cm = confusion_matrix(y3_val, y_pred_ens, labels=le.classes_)\n",
    "print(\"\\n[Confusion Matrix - VotingClassifier (Soft)]\")\n",
    "print(\"Labels:\", list(le.classes_))\n",
    "print(cm)\n",
    "\n",
    "# âœ… 7. ì •í™•ë„ & F1-score ì‹œê°í™”\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [\n",
    "        report_df_ens.loc['accuracy']['precision'],  # accuracyëŠ” precision keyì— ì €ì¥ë¨\n",
    "        report_df_ens.loc['weighted avg']['f1-score']\n",
    "    ]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('VotingClassifier ì„±ëŠ¥ (SMOTE + XGBoost + CatBoost)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYgK2GfdTgCr"
   },
   "source": [
    "SMOTE : LGBM + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f8d09a1618f541df816123ca20720bc4",
      "75493f23840a4c34bbe7e44f9ab4ee1d",
      "ee6177e320fe42cd985dafda1f27c26c",
      "6a56f41b50ff481d840cce02702b1d5e",
      "b9f9166d77a34880bb1f73d8f51d01e0",
      "8d7877fbf7d440d9aa9cc41ecbff7b6a",
      "8ef8c282c65741438198fa7a715e40e6",
      "23c570a35d3041fd86185559f05360ce",
      "8ad1e148273d400bb310b1a335053f67",
      "6d310c1c51df47db81f8ea5b361a3a09",
      "cc5c13238ba14a0d8bfa645101757aaa"
     ]
    },
    "collapsed": true,
    "id": "Gy_3rosIUW7G",
    "outputId": "a850d0da-5265-4193-bc91-6b4ea66f5aae"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import randint, uniform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y3_tr_smote_enc = le.fit_transform(y3_tr_smote)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# 2. íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ ì •ì˜\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'num_leaves': randint(15, 50),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'reg_alpha': uniform(0, 5),\n",
    "    'reg_lambda': uniform(0, 5)\n",
    "}\n",
    "\n",
    "# 3. LGBM ëª¨ë¸ ì •ì˜\n",
    "lgbm = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. ì§„í–‰ë¥  í¬í•¨ RandomizedSearchCV í´ë˜ìŠ¤ ì •ì˜\n",
    "class TqdmRandomizedSearchCV(RandomizedSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        with tqdm(total=self.n_iter, desc=\"ğŸ” LGBM Random Search\") as pbar:\n",
    "            self._pbar = pbar\n",
    "            return super().fit(X, y, **fit_params)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        def wrapped(candidate_params):\n",
    "            results = evaluate_candidates(candidate_params)\n",
    "            self._pbar.update(len(candidate_params))\n",
    "            return results\n",
    "        return super()._run_search(wrapped)\n",
    "\n",
    "# 5. íƒìƒ‰ê¸° ì •ì˜ ë° í•™ìŠµ\n",
    "random_search_lgbm = TqdmRandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_lgbm.fit(X3_tr_smote, y3_tr_smote_enc)\n",
    "\n",
    "# 6. ìµœì  ëª¨ë¸ í‰ê°€\n",
    "best_lgbm = random_search_lgbm.best_estimator_\n",
    "y3_pred_enc = best_lgbm.predict(X3_val)\n",
    "y3_pred = le.inverse_transform(y3_pred_enc)\n",
    "\n",
    "# 7. ë¦¬í¬íŠ¸ ë° ì‹œê°í™”\n",
    "report_lgbm = classification_report(y3_val, y3_pred, output_dict=True)\n",
    "report_df_lgbm = pd.DataFrame(report_lgbm).transpose()\n",
    "\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df_lgbm.loc['accuracy']['precision'], report_df_lgbm.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ LGBM ì„±ëŠ¥ (Random Search)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(\"LGBM ìµœì  íŒŒë¼ë¯¸í„°:\", random_search_lgbm.best_params_)\n",
    "print(\"LGBM ì„±ëŠ¥ ìƒì„¸:\")\n",
    "print(report_df_lgbm[['precision', 'recall', 'f1-score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkfsOYC5Yy2S"
   },
   "source": [
    "Soft Voting ì•™ìƒë¸” (SMOTE ê¸°ë°˜ XGB + CAT + LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "cqnZml_KYwe_",
    "outputId": "7fa951ef-af9e-4fd6-e6c4-51833a0bb8d8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. ë ˆì´ë¸” ì¸ì½”ë”© (ì¬ì‚¬ìš©)\n",
    "y3_val_enc = le.transform(y3_val)\n",
    "\n",
    "# 2. Soft Voting ì•™ìƒë¸” êµ¬ì„±\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('cat', best_cat),\n",
    "        ('lgbm', best_lgbm)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. ì•™ìƒë¸” í•™ìŠµ\n",
    "voting_clf.fit(X3_tr_smote, y3_tr_smote_enc)\n",
    "\n",
    "# 4. ì˜ˆì¸¡ ë° ì—­ë³€í™˜\n",
    "y_pred_enc = voting_clf.predict(X3_val)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "\n",
    "# 5. ì„±ëŠ¥ í‰ê°€\n",
    "report = classification_report(y3_val, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 6. Confusion Matrix\n",
    "cm = confusion_matrix(y3_val, y_pred, labels=le.classes_)\n",
    "\n",
    "# 7. ì •í™•ë„ ë° f1-score ì‹œê°í™”\n",
    "score_df = pd.DataFrame({\n",
    "    'Metric': ['accuracy', 'f1-score'],\n",
    "    'Score': [report_df.loc['accuracy']['precision'], report_df.loc['weighted avg']['f1-score']]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=score_df, x='Metric', y='Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('SMOTE ê¸°ë°˜ Soft Voting ì•™ìƒë¸” ì„±ëŠ¥ (XGB+CAT+LGBM)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. ì¶œë ¥\n",
    "print(\"\\n[3-Class Classification Report - VotingClassifier (Soft)]\")\n",
    "print(report_df[['precision', 'recall', 'f1-score']].round(3))\n",
    "\n",
    "print(\"\\n[Confusion Matrix - VotingClassifier (Soft)]\")\n",
    "print(\"Labels:\", le.classes_.tolist())\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
